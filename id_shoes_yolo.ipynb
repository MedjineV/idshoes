{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impossible-portugal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/nathan/.cache/torch/hub/ultralytics_yolov5_master\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     70122  models.yolo.Detect                      [21, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7117482 parameters, 7117482 gradients, 16.5 GFLOPS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding autoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path_or_model=\"/home/nathan/code/yolo/yolov5/yolo_weights/yolov5s/exp/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "severe-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "])\n",
    "image = np.array(Image.open(\"/home/nathan/id_shoes_pictures/par_modele/pictures/AQS100/20210211_154619.jpg\"))\n",
    "\n",
    "model.eval()\n",
    "# predicted = model(Image.open(\"/home/nathan/id_shoes_pictures/pictures/TBS/TBS 3/IMG_0452.JPG\"))\n",
    "predicted = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "powered-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\"0\":\"TBS 1\", \n",
    "\"1\":\"TBS 2\",\n",
    "\"2\":\"TBS 3\",\n",
    "\"3\":\"TBS 4\",\n",
    "\"4\":\"TBS 5\",\n",
    "\"5\":\"TBS 6\",\n",
    "\"6\":\"TBS 7\",\n",
    "\"7\":\"TBS 8\",\n",
    "\"8\":\"TBS 9\",\n",
    "\"9\":\"TBS 10\",\n",
    "\"10\":\"TBS 11\",\n",
    "\"11\":\"TBS 12\",\n",
    "\"12\":\"TBS 13\",\n",
    "\"13\":\"TBS 14\",\n",
    "\"14\":\"TBS 15\",\n",
    "\"15\":\"AQS100\",\n",
    "\"16\":\"AQS120\",\n",
    "\"17\":\"AQUADOTS\",\n",
    "\"18\":\"AQUAFUN\",\n",
    "\"19\":\"SAILING100\",\n",
    "\"20\":\"BOCAGE 1\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "potential-washer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AQUADOTS'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[str(int(predicted.xyxy[0][predicted.xyxy[0].max(0)[1][4].item()][5].item()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "administrative-import",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3264, 2448)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(\"/home/nathan/id_shoes_pictures/pictures/TBS/TBS 3/IMG_0452.JPG\").size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equipped-desktop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.16580e+02, 8.83374e+02, 3.40722e+03, 2.57608e+03, 7.64878e-01, 1.50000e+01]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.xyxy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "single-northeast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7648781538009644"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.xyxy[0].max(0)[0][4].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-bermuda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
